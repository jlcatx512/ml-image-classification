{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml-clothing-classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0sZLTegHBWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLR8kAbAHKrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvf archive.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xHCvg8_HK0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vAyQwE6HK6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg19 import (\n",
        "    VGG19, preprocess_input, decode_predictions)\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import merge, Input\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical, np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVZZ3dz8HK9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tm3MsjB3cDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.train_path = \"Resources/train\"\n",
        "data.test_path = \"Resources/test\"\n",
        "folder_names = [\"pants\", \"purse\",\"skirt\",\"sneaker\",\"sweater\",\"t-shirt\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OeSdn2U3mv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2b4c4a73-77ca-467c-86ef-167e8d7dea47"
      },
      "source": [
        "X_train, Y_train = data.get_images(data.train_path, folder_names)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resources/train/sweater/*\n",
            "Loaded the images of dataset-sweater\n",
            "\n",
            "Resources/train/sneaker/*\n",
            "Loaded the images of dataset-sneaker\n",
            "\n",
            "Resources/train/skirt/*\n",
            "Loaded the images of dataset-skirt\n",
            "\n",
            "Resources/train/pants/*\n",
            "Loaded the images of dataset-pants\n",
            "\n",
            "Resources/train/t-shirt/*\n",
            "Loaded the images of dataset-t-shirt\n",
            "\n",
            "Resources/train/purse/*\n",
            "Loaded the images of dataset-purse\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I71MGD23wgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "c6c89af8-5b3a-4853-8931-9d8b08eba3fd"
      },
      "source": [
        "X_test, Y_test = data.get_images(data.test_path, folder_names)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resources/test/sweater/*\n",
            "Loaded the images of dataset-sweater\n",
            "\n",
            "Resources/test/sneaker/*\n",
            "Loaded the images of dataset-sneaker\n",
            "\n",
            "Resources/test/skirt/*\n",
            "Loaded the images of dataset-skirt\n",
            "\n",
            "Resources/test/pants/*\n",
            "Loaded the images of dataset-pants\n",
            "\n",
            "Resources/test/t-shirt/*\n",
            "Loaded the images of dataset-t-shirt\n",
            "\n",
            "Resources/test/purse/*\n",
            "Loaded the images of dataset-purse\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHPDG_El322i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b277f32-3d5d-4974-8329-478aed00982f"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(282, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1wEVxYm4CyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_input = Input(shape=(224,224,3))\n",
        "\n",
        "vgg_model = VGG19(input_tensor=image_input,include_top=True, weights='imagenet')\n",
        "vgg_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlBLnysFcFcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_features = vgg_model.predict(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Awcvw4ucI-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_features = vgg_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtbcVY6Ec3At",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the 1000 category output like a set of features into a new model\n",
        "\n",
        "feature_model = Sequential()\n",
        "feature_model.add(Dense(data.num_classes, activation=\"sigmoid\", input_shape=(1000,)))\n",
        "feature_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcdQHI4ifFhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "476316ce-384a-4128-a923-a09b566fa753"
      },
      "source": [
        "feature_model.fit(X_train_features, Y_train, epochs=200, validation_data=(X_test_features, Y_test))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 282 samples, validate on 117 samples\n",
            "Epoch 1/200\n",
            "282/282 [==============================] - 0s 165us/step - loss: 0.7170 - acc: 0.9645 - val_loss: 0.8464 - val_acc: 0.9145\n",
            "Epoch 2/200\n",
            "282/282 [==============================] - 0s 121us/step - loss: 0.7131 - acc: 0.9645 - val_loss: 0.8430 - val_acc: 0.9145\n",
            "Epoch 3/200\n",
            "282/282 [==============================] - 0s 112us/step - loss: 0.7092 - acc: 0.9645 - val_loss: 0.8395 - val_acc: 0.9145\n",
            "Epoch 4/200\n",
            "282/282 [==============================] - 0s 109us/step - loss: 0.7053 - acc: 0.9645 - val_loss: 0.8360 - val_acc: 0.9145\n",
            "Epoch 5/200\n",
            "282/282 [==============================] - 0s 126us/step - loss: 0.7015 - acc: 0.9645 - val_loss: 0.8327 - val_acc: 0.9145\n",
            "Epoch 6/200\n",
            "282/282 [==============================] - 0s 128us/step - loss: 0.6976 - acc: 0.9645 - val_loss: 0.8294 - val_acc: 0.9145\n",
            "Epoch 7/200\n",
            "282/282 [==============================] - 0s 132us/step - loss: 0.6938 - acc: 0.9645 - val_loss: 0.8261 - val_acc: 0.9145\n",
            "Epoch 8/200\n",
            "282/282 [==============================] - 0s 119us/step - loss: 0.6901 - acc: 0.9645 - val_loss: 0.8228 - val_acc: 0.9145\n",
            "Epoch 9/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.6864 - acc: 0.9645 - val_loss: 0.8194 - val_acc: 0.9145\n",
            "Epoch 10/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.6827 - acc: 0.9645 - val_loss: 0.8162 - val_acc: 0.9145\n",
            "Epoch 11/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.6790 - acc: 0.9645 - val_loss: 0.8130 - val_acc: 0.9145\n",
            "Epoch 12/200\n",
            "282/282 [==============================] - 0s 120us/step - loss: 0.6754 - acc: 0.9645 - val_loss: 0.8098 - val_acc: 0.9145\n",
            "Epoch 13/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.6718 - acc: 0.9645 - val_loss: 0.8066 - val_acc: 0.9145\n",
            "Epoch 14/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.6682 - acc: 0.9645 - val_loss: 0.8034 - val_acc: 0.9145\n",
            "Epoch 15/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.6646 - acc: 0.9645 - val_loss: 0.8002 - val_acc: 0.9145\n",
            "Epoch 16/200\n",
            "282/282 [==============================] - 0s 126us/step - loss: 0.6611 - acc: 0.9645 - val_loss: 0.7972 - val_acc: 0.9145\n",
            "Epoch 17/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.6576 - acc: 0.9645 - val_loss: 0.7941 - val_acc: 0.9145\n",
            "Epoch 18/200\n",
            "282/282 [==============================] - 0s 125us/step - loss: 0.6541 - acc: 0.9645 - val_loss: 0.7910 - val_acc: 0.9145\n",
            "Epoch 19/200\n",
            "282/282 [==============================] - 0s 137us/step - loss: 0.6506 - acc: 0.9645 - val_loss: 0.7879 - val_acc: 0.9145\n",
            "Epoch 20/200\n",
            "282/282 [==============================] - 0s 135us/step - loss: 0.6472 - acc: 0.9645 - val_loss: 0.7849 - val_acc: 0.9145\n",
            "Epoch 21/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.6438 - acc: 0.9645 - val_loss: 0.7819 - val_acc: 0.9145\n",
            "Epoch 22/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.6404 - acc: 0.9645 - val_loss: 0.7789 - val_acc: 0.9145\n",
            "Epoch 23/200\n",
            "282/282 [==============================] - 0s 107us/step - loss: 0.6371 - acc: 0.9645 - val_loss: 0.7759 - val_acc: 0.9145\n",
            "Epoch 24/200\n",
            "282/282 [==============================] - 0s 120us/step - loss: 0.6337 - acc: 0.9645 - val_loss: 0.7730 - val_acc: 0.9145\n",
            "Epoch 25/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.6304 - acc: 0.9645 - val_loss: 0.7701 - val_acc: 0.9145\n",
            "Epoch 26/200\n",
            "282/282 [==============================] - 0s 119us/step - loss: 0.6272 - acc: 0.9645 - val_loss: 0.7672 - val_acc: 0.9145\n",
            "Epoch 27/200\n",
            "282/282 [==============================] - 0s 127us/step - loss: 0.6239 - acc: 0.9645 - val_loss: 0.7644 - val_acc: 0.9145\n",
            "Epoch 28/200\n",
            "282/282 [==============================] - 0s 108us/step - loss: 0.6207 - acc: 0.9645 - val_loss: 0.7615 - val_acc: 0.9145\n",
            "Epoch 29/200\n",
            "282/282 [==============================] - 0s 119us/step - loss: 0.6175 - acc: 0.9645 - val_loss: 0.7587 - val_acc: 0.9145\n",
            "Epoch 30/200\n",
            "282/282 [==============================] - 0s 127us/step - loss: 0.6143 - acc: 0.9645 - val_loss: 0.7559 - val_acc: 0.9145\n",
            "Epoch 31/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.6111 - acc: 0.9645 - val_loss: 0.7532 - val_acc: 0.9145\n",
            "Epoch 32/200\n",
            "282/282 [==============================] - 0s 109us/step - loss: 0.6081 - acc: 0.9645 - val_loss: 0.7503 - val_acc: 0.9145\n",
            "Epoch 33/200\n",
            "282/282 [==============================] - 0s 133us/step - loss: 0.6049 - acc: 0.9645 - val_loss: 0.7476 - val_acc: 0.9145\n",
            "Epoch 34/200\n",
            "282/282 [==============================] - 0s 117us/step - loss: 0.6018 - acc: 0.9645 - val_loss: 0.7449 - val_acc: 0.9145\n",
            "Epoch 35/200\n",
            "282/282 [==============================] - 0s 112us/step - loss: 0.5988 - acc: 0.9645 - val_loss: 0.7422 - val_acc: 0.9145\n",
            "Epoch 36/200\n",
            "282/282 [==============================] - 0s 108us/step - loss: 0.5957 - acc: 0.9645 - val_loss: 0.7395 - val_acc: 0.9145\n",
            "Epoch 37/200\n",
            "282/282 [==============================] - 0s 117us/step - loss: 0.5927 - acc: 0.9645 - val_loss: 0.7369 - val_acc: 0.9145\n",
            "Epoch 38/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.5898 - acc: 0.9645 - val_loss: 0.7343 - val_acc: 0.9145\n",
            "Epoch 39/200\n",
            "282/282 [==============================] - 0s 125us/step - loss: 0.5868 - acc: 0.9645 - val_loss: 0.7316 - val_acc: 0.9145\n",
            "Epoch 40/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.5839 - acc: 0.9645 - val_loss: 0.7290 - val_acc: 0.9145\n",
            "Epoch 41/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.5809 - acc: 0.9645 - val_loss: 0.7265 - val_acc: 0.9145\n",
            "Epoch 42/200\n",
            "282/282 [==============================] - 0s 109us/step - loss: 0.5780 - acc: 0.9645 - val_loss: 0.7239 - val_acc: 0.9145\n",
            "Epoch 43/200\n",
            "282/282 [==============================] - 0s 125us/step - loss: 0.5752 - acc: 0.9645 - val_loss: 0.7214 - val_acc: 0.9145\n",
            "Epoch 44/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.5723 - acc: 0.9645 - val_loss: 0.7189 - val_acc: 0.9145\n",
            "Epoch 45/200\n",
            "282/282 [==============================] - 0s 109us/step - loss: 0.5695 - acc: 0.9645 - val_loss: 0.7164 - val_acc: 0.9145\n",
            "Epoch 46/200\n",
            "282/282 [==============================] - 0s 119us/step - loss: 0.5667 - acc: 0.9645 - val_loss: 0.7140 - val_acc: 0.9145\n",
            "Epoch 47/200\n",
            "282/282 [==============================] - 0s 119us/step - loss: 0.5639 - acc: 0.9645 - val_loss: 0.7115 - val_acc: 0.9145\n",
            "Epoch 48/200\n",
            "282/282 [==============================] - 0s 131us/step - loss: 0.5611 - acc: 0.9645 - val_loss: 0.7091 - val_acc: 0.9145\n",
            "Epoch 49/200\n",
            "282/282 [==============================] - 0s 148us/step - loss: 0.5584 - acc: 0.9645 - val_loss: 0.7066 - val_acc: 0.9145\n",
            "Epoch 50/200\n",
            "282/282 [==============================] - 0s 116us/step - loss: 0.5556 - acc: 0.9645 - val_loss: 0.7042 - val_acc: 0.9145\n",
            "Epoch 51/200\n",
            "282/282 [==============================] - 0s 116us/step - loss: 0.5529 - acc: 0.9645 - val_loss: 0.7018 - val_acc: 0.9145\n",
            "Epoch 52/200\n",
            "282/282 [==============================] - 0s 131us/step - loss: 0.5503 - acc: 0.9645 - val_loss: 0.6995 - val_acc: 0.9145\n",
            "Epoch 53/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.5476 - acc: 0.9645 - val_loss: 0.6971 - val_acc: 0.9145\n",
            "Epoch 54/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.5450 - acc: 0.9645 - val_loss: 0.6947 - val_acc: 0.9145\n",
            "Epoch 55/200\n",
            "282/282 [==============================] - 0s 123us/step - loss: 0.5423 - acc: 0.9645 - val_loss: 0.6925 - val_acc: 0.9145\n",
            "Epoch 56/200\n",
            "282/282 [==============================] - 0s 122us/step - loss: 0.5397 - acc: 0.9645 - val_loss: 0.6902 - val_acc: 0.9145\n",
            "Epoch 57/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.5372 - acc: 0.9645 - val_loss: 0.6879 - val_acc: 0.9145\n",
            "Epoch 58/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.5346 - acc: 0.9645 - val_loss: 0.6857 - val_acc: 0.9145\n",
            "Epoch 59/200\n",
            "282/282 [==============================] - 0s 116us/step - loss: 0.5321 - acc: 0.9645 - val_loss: 0.6834 - val_acc: 0.9145\n",
            "Epoch 60/200\n",
            "282/282 [==============================] - 0s 122us/step - loss: 0.5296 - acc: 0.9645 - val_loss: 0.6812 - val_acc: 0.9145\n",
            "Epoch 61/200\n",
            "282/282 [==============================] - 0s 122us/step - loss: 0.5270 - acc: 0.9645 - val_loss: 0.6790 - val_acc: 0.9145\n",
            "Epoch 62/200\n",
            "282/282 [==============================] - 0s 112us/step - loss: 0.5245 - acc: 0.9645 - val_loss: 0.6768 - val_acc: 0.9145\n",
            "Epoch 63/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.5221 - acc: 0.9645 - val_loss: 0.6746 - val_acc: 0.9145\n",
            "Epoch 64/200\n",
            "282/282 [==============================] - 0s 117us/step - loss: 0.5196 - acc: 0.9645 - val_loss: 0.6724 - val_acc: 0.9145\n",
            "Epoch 65/200\n",
            "282/282 [==============================] - 0s 107us/step - loss: 0.5172 - acc: 0.9645 - val_loss: 0.6703 - val_acc: 0.9145\n",
            "Epoch 66/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.5148 - acc: 0.9645 - val_loss: 0.6682 - val_acc: 0.9145\n",
            "Epoch 67/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.5124 - acc: 0.9645 - val_loss: 0.6661 - val_acc: 0.9145\n",
            "Epoch 68/200\n",
            "282/282 [==============================] - 0s 121us/step - loss: 0.5100 - acc: 0.9645 - val_loss: 0.6640 - val_acc: 0.9145\n",
            "Epoch 69/200\n",
            "282/282 [==============================] - 0s 127us/step - loss: 0.5077 - acc: 0.9645 - val_loss: 0.6619 - val_acc: 0.9145\n",
            "Epoch 70/200\n",
            "282/282 [==============================] - 0s 112us/step - loss: 0.5053 - acc: 0.9645 - val_loss: 0.6598 - val_acc: 0.9145\n",
            "Epoch 71/200\n",
            "282/282 [==============================] - 0s 105us/step - loss: 0.5030 - acc: 0.9645 - val_loss: 0.6578 - val_acc: 0.9145\n",
            "Epoch 72/200\n",
            "282/282 [==============================] - 0s 116us/step - loss: 0.5007 - acc: 0.9645 - val_loss: 0.6558 - val_acc: 0.9145\n",
            "Epoch 73/200\n",
            "282/282 [==============================] - 0s 100us/step - loss: 0.4984 - acc: 0.9645 - val_loss: 0.6538 - val_acc: 0.9145\n",
            "Epoch 74/200\n",
            "282/282 [==============================] - 0s 129us/step - loss: 0.4962 - acc: 0.9645 - val_loss: 0.6518 - val_acc: 0.9145\n",
            "Epoch 75/200\n",
            "282/282 [==============================] - 0s 138us/step - loss: 0.4939 - acc: 0.9645 - val_loss: 0.6498 - val_acc: 0.9145\n",
            "Epoch 76/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.4917 - acc: 0.9645 - val_loss: 0.6478 - val_acc: 0.9145\n",
            "Epoch 77/200\n",
            "282/282 [==============================] - 0s 105us/step - loss: 0.4895 - acc: 0.9645 - val_loss: 0.6459 - val_acc: 0.9145\n",
            "Epoch 78/200\n",
            "282/282 [==============================] - 0s 117us/step - loss: 0.4873 - acc: 0.9645 - val_loss: 0.6440 - val_acc: 0.9145\n",
            "Epoch 79/200\n",
            "282/282 [==============================] - 0s 142us/step - loss: 0.4851 - acc: 0.9645 - val_loss: 0.6420 - val_acc: 0.9145\n",
            "Epoch 80/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.4829 - acc: 0.9645 - val_loss: 0.6401 - val_acc: 0.9145\n",
            "Epoch 81/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.4808 - acc: 0.9645 - val_loss: 0.6382 - val_acc: 0.9145\n",
            "Epoch 82/200\n",
            "282/282 [==============================] - 0s 126us/step - loss: 0.4786 - acc: 0.9681 - val_loss: 0.6363 - val_acc: 0.9145\n",
            "Epoch 83/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.4765 - acc: 0.9681 - val_loss: 0.6345 - val_acc: 0.9145\n",
            "Epoch 84/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.4744 - acc: 0.9681 - val_loss: 0.6327 - val_acc: 0.9145\n",
            "Epoch 85/200\n",
            "282/282 [==============================] - 0s 106us/step - loss: 0.4723 - acc: 0.9681 - val_loss: 0.6308 - val_acc: 0.9145\n",
            "Epoch 86/200\n",
            "282/282 [==============================] - 0s 126us/step - loss: 0.4702 - acc: 0.9681 - val_loss: 0.6290 - val_acc: 0.9145\n",
            "Epoch 87/200\n",
            "282/282 [==============================] - 0s 127us/step - loss: 0.4682 - acc: 0.9681 - val_loss: 0.6272 - val_acc: 0.9145\n",
            "Epoch 88/200\n",
            "282/282 [==============================] - 0s 126us/step - loss: 0.4661 - acc: 0.9681 - val_loss: 0.6254 - val_acc: 0.9145\n",
            "Epoch 89/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.4641 - acc: 0.9681 - val_loss: 0.6236 - val_acc: 0.9145\n",
            "Epoch 90/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.4621 - acc: 0.9681 - val_loss: 0.6218 - val_acc: 0.9145\n",
            "Epoch 91/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.4601 - acc: 0.9681 - val_loss: 0.6201 - val_acc: 0.9145\n",
            "Epoch 92/200\n",
            "282/282 [==============================] - 0s 105us/step - loss: 0.4581 - acc: 0.9681 - val_loss: 0.6184 - val_acc: 0.9145\n",
            "Epoch 93/200\n",
            "282/282 [==============================] - 0s 100us/step - loss: 0.4561 - acc: 0.9681 - val_loss: 0.6166 - val_acc: 0.9145\n",
            "Epoch 94/200\n",
            "282/282 [==============================] - 0s 106us/step - loss: 0.4542 - acc: 0.9681 - val_loss: 0.6149 - val_acc: 0.9145\n",
            "Epoch 95/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.4522 - acc: 0.9681 - val_loss: 0.6132 - val_acc: 0.9145\n",
            "Epoch 96/200\n",
            "282/282 [==============================] - 0s 97us/step - loss: 0.4503 - acc: 0.9681 - val_loss: 0.6115 - val_acc: 0.9145\n",
            "Epoch 97/200\n",
            "282/282 [==============================] - 0s 114us/step - loss: 0.4484 - acc: 0.9681 - val_loss: 0.6098 - val_acc: 0.9145\n",
            "Epoch 98/200\n",
            "282/282 [==============================] - 0s 127us/step - loss: 0.4465 - acc: 0.9681 - val_loss: 0.6082 - val_acc: 0.9145\n",
            "Epoch 99/200\n",
            "282/282 [==============================] - 0s 122us/step - loss: 0.4446 - acc: 0.9681 - val_loss: 0.6065 - val_acc: 0.9145\n",
            "Epoch 100/200\n",
            "282/282 [==============================] - 0s 158us/step - loss: 0.4427 - acc: 0.9681 - val_loss: 0.6049 - val_acc: 0.9145\n",
            "Epoch 101/200\n",
            "282/282 [==============================] - 0s 121us/step - loss: 0.4408 - acc: 0.9681 - val_loss: 0.6032 - val_acc: 0.9145\n",
            "Epoch 102/200\n",
            "282/282 [==============================] - 0s 112us/step - loss: 0.4390 - acc: 0.9681 - val_loss: 0.6016 - val_acc: 0.9145\n",
            "Epoch 103/200\n",
            "282/282 [==============================] - 0s 126us/step - loss: 0.4372 - acc: 0.9681 - val_loss: 0.6000 - val_acc: 0.9145\n",
            "Epoch 104/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.4353 - acc: 0.9681 - val_loss: 0.5984 - val_acc: 0.9145\n",
            "Epoch 105/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.4335 - acc: 0.9716 - val_loss: 0.5968 - val_acc: 0.9145\n",
            "Epoch 106/200\n",
            "282/282 [==============================] - 0s 124us/step - loss: 0.4317 - acc: 0.9716 - val_loss: 0.5953 - val_acc: 0.9145\n",
            "Epoch 107/200\n",
            "282/282 [==============================] - 0s 116us/step - loss: 0.4300 - acc: 0.9716 - val_loss: 0.5937 - val_acc: 0.9145\n",
            "Epoch 108/200\n",
            "282/282 [==============================] - 0s 105us/step - loss: 0.4282 - acc: 0.9716 - val_loss: 0.5922 - val_acc: 0.9145\n",
            "Epoch 109/200\n",
            "282/282 [==============================] - 0s 145us/step - loss: 0.4264 - acc: 0.9716 - val_loss: 0.5906 - val_acc: 0.9145\n",
            "Epoch 110/200\n",
            "282/282 [==============================] - 0s 135us/step - loss: 0.4247 - acc: 0.9716 - val_loss: 0.5891 - val_acc: 0.9145\n",
            "Epoch 111/200\n",
            "282/282 [==============================] - 0s 127us/step - loss: 0.4230 - acc: 0.9716 - val_loss: 0.5876 - val_acc: 0.9145\n",
            "Epoch 112/200\n",
            "282/282 [==============================] - 0s 117us/step - loss: 0.4213 - acc: 0.9716 - val_loss: 0.5861 - val_acc: 0.9145\n",
            "Epoch 113/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.4196 - acc: 0.9716 - val_loss: 0.5846 - val_acc: 0.9145\n",
            "Epoch 114/200\n",
            "282/282 [==============================] - 0s 123us/step - loss: 0.4178 - acc: 0.9716 - val_loss: 0.5831 - val_acc: 0.9145\n",
            "Epoch 115/200\n",
            "282/282 [==============================] - 0s 108us/step - loss: 0.4162 - acc: 0.9716 - val_loss: 0.5816 - val_acc: 0.9145\n",
            "Epoch 116/200\n",
            "282/282 [==============================] - 0s 120us/step - loss: 0.4145 - acc: 0.9716 - val_loss: 0.5801 - val_acc: 0.9145\n",
            "Epoch 117/200\n",
            "282/282 [==============================] - 0s 127us/step - loss: 0.4128 - acc: 0.9716 - val_loss: 0.5787 - val_acc: 0.9145\n",
            "Epoch 118/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.4112 - acc: 0.9716 - val_loss: 0.5772 - val_acc: 0.9145\n",
            "Epoch 119/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.4096 - acc: 0.9716 - val_loss: 0.5758 - val_acc: 0.9145\n",
            "Epoch 120/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.4079 - acc: 0.9716 - val_loss: 0.5744 - val_acc: 0.9145\n",
            "Epoch 121/200\n",
            "282/282 [==============================] - 0s 109us/step - loss: 0.4063 - acc: 0.9716 - val_loss: 0.5730 - val_acc: 0.9145\n",
            "Epoch 122/200\n",
            "282/282 [==============================] - 0s 114us/step - loss: 0.4047 - acc: 0.9716 - val_loss: 0.5716 - val_acc: 0.9145\n",
            "Epoch 123/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.4031 - acc: 0.9716 - val_loss: 0.5702 - val_acc: 0.9145\n",
            "Epoch 124/200\n",
            "282/282 [==============================] - 0s 125us/step - loss: 0.4015 - acc: 0.9716 - val_loss: 0.5688 - val_acc: 0.9145\n",
            "Epoch 125/200\n",
            "282/282 [==============================] - 0s 112us/step - loss: 0.4000 - acc: 0.9716 - val_loss: 0.5674 - val_acc: 0.9145\n",
            "Epoch 126/200\n",
            "282/282 [==============================] - 0s 108us/step - loss: 0.3984 - acc: 0.9716 - val_loss: 0.5661 - val_acc: 0.9145\n",
            "Epoch 127/200\n",
            "282/282 [==============================] - 0s 98us/step - loss: 0.3969 - acc: 0.9716 - val_loss: 0.5647 - val_acc: 0.9145\n",
            "Epoch 128/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.3953 - acc: 0.9716 - val_loss: 0.5634 - val_acc: 0.9145\n",
            "Epoch 129/200\n",
            "282/282 [==============================] - 0s 134us/step - loss: 0.3938 - acc: 0.9716 - val_loss: 0.5621 - val_acc: 0.9145\n",
            "Epoch 130/200\n",
            "282/282 [==============================] - 0s 124us/step - loss: 0.3923 - acc: 0.9716 - val_loss: 0.5607 - val_acc: 0.9145\n",
            "Epoch 131/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.3908 - acc: 0.9716 - val_loss: 0.5594 - val_acc: 0.9145\n",
            "Epoch 132/200\n",
            "282/282 [==============================] - 0s 124us/step - loss: 0.3893 - acc: 0.9716 - val_loss: 0.5581 - val_acc: 0.9145\n",
            "Epoch 133/200\n",
            "282/282 [==============================] - 0s 112us/step - loss: 0.3878 - acc: 0.9716 - val_loss: 0.5568 - val_acc: 0.9145\n",
            "Epoch 134/200\n",
            "282/282 [==============================] - 0s 108us/step - loss: 0.3863 - acc: 0.9716 - val_loss: 0.5556 - val_acc: 0.9145\n",
            "Epoch 135/200\n",
            "282/282 [==============================] - 0s 120us/step - loss: 0.3849 - acc: 0.9716 - val_loss: 0.5543 - val_acc: 0.9145\n",
            "Epoch 136/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.3834 - acc: 0.9716 - val_loss: 0.5530 - val_acc: 0.9145\n",
            "Epoch 137/200\n",
            "282/282 [==============================] - 0s 114us/step - loss: 0.3820 - acc: 0.9716 - val_loss: 0.5517 - val_acc: 0.9145\n",
            "Epoch 138/200\n",
            "282/282 [==============================] - 0s 132us/step - loss: 0.3805 - acc: 0.9716 - val_loss: 0.5505 - val_acc: 0.9145\n",
            "Epoch 139/200\n",
            "282/282 [==============================] - 0s 128us/step - loss: 0.3791 - acc: 0.9716 - val_loss: 0.5492 - val_acc: 0.9145\n",
            "Epoch 140/200\n",
            "282/282 [==============================] - 0s 112us/step - loss: 0.3777 - acc: 0.9716 - val_loss: 0.5480 - val_acc: 0.9145\n",
            "Epoch 141/200\n",
            "282/282 [==============================] - 0s 121us/step - loss: 0.3763 - acc: 0.9716 - val_loss: 0.5468 - val_acc: 0.9145\n",
            "Epoch 142/200\n",
            "282/282 [==============================] - 0s 104us/step - loss: 0.3749 - acc: 0.9716 - val_loss: 0.5456 - val_acc: 0.9145\n",
            "Epoch 143/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.3735 - acc: 0.9716 - val_loss: 0.5444 - val_acc: 0.9145\n",
            "Epoch 144/200\n",
            "282/282 [==============================] - 0s 122us/step - loss: 0.3721 - acc: 0.9716 - val_loss: 0.5431 - val_acc: 0.9145\n",
            "Epoch 145/200\n",
            "282/282 [==============================] - 0s 132us/step - loss: 0.3707 - acc: 0.9716 - val_loss: 0.5419 - val_acc: 0.9145\n",
            "Epoch 146/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.3694 - acc: 0.9716 - val_loss: 0.5408 - val_acc: 0.9145\n",
            "Epoch 147/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.3680 - acc: 0.9716 - val_loss: 0.5396 - val_acc: 0.9145\n",
            "Epoch 148/200\n",
            "282/282 [==============================] - 0s 124us/step - loss: 0.3667 - acc: 0.9716 - val_loss: 0.5384 - val_acc: 0.9145\n",
            "Epoch 149/200\n",
            "282/282 [==============================] - 0s 120us/step - loss: 0.3653 - acc: 0.9716 - val_loss: 0.5373 - val_acc: 0.9145\n",
            "Epoch 150/200\n",
            "282/282 [==============================] - 0s 117us/step - loss: 0.3640 - acc: 0.9716 - val_loss: 0.5361 - val_acc: 0.9145\n",
            "Epoch 151/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.3627 - acc: 0.9716 - val_loss: 0.5350 - val_acc: 0.9145\n",
            "Epoch 152/200\n",
            "282/282 [==============================] - 0s 114us/step - loss: 0.3614 - acc: 0.9716 - val_loss: 0.5338 - val_acc: 0.9145\n",
            "Epoch 153/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.3601 - acc: 0.9716 - val_loss: 0.5327 - val_acc: 0.9145\n",
            "Epoch 154/200\n",
            "282/282 [==============================] - 0s 106us/step - loss: 0.3588 - acc: 0.9716 - val_loss: 0.5316 - val_acc: 0.9145\n",
            "Epoch 155/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.3575 - acc: 0.9716 - val_loss: 0.5305 - val_acc: 0.9145\n",
            "Epoch 156/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.3562 - acc: 0.9716 - val_loss: 0.5294 - val_acc: 0.9145\n",
            "Epoch 157/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.3550 - acc: 0.9716 - val_loss: 0.5283 - val_acc: 0.9145\n",
            "Epoch 158/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.3537 - acc: 0.9716 - val_loss: 0.5272 - val_acc: 0.9145\n",
            "Epoch 159/200\n",
            "282/282 [==============================] - 0s 140us/step - loss: 0.3525 - acc: 0.9716 - val_loss: 0.5261 - val_acc: 0.9145\n",
            "Epoch 160/200\n",
            "282/282 [==============================] - 0s 114us/step - loss: 0.3512 - acc: 0.9716 - val_loss: 0.5251 - val_acc: 0.9145\n",
            "Epoch 161/200\n",
            "282/282 [==============================] - 0s 134us/step - loss: 0.3500 - acc: 0.9716 - val_loss: 0.5240 - val_acc: 0.9145\n",
            "Epoch 162/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.3488 - acc: 0.9716 - val_loss: 0.5229 - val_acc: 0.9145\n",
            "Epoch 163/200\n",
            "282/282 [==============================] - 0s 119us/step - loss: 0.3475 - acc: 0.9716 - val_loss: 0.5219 - val_acc: 0.9145\n",
            "Epoch 164/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.3463 - acc: 0.9716 - val_loss: 0.5208 - val_acc: 0.9145\n",
            "Epoch 165/200\n",
            "282/282 [==============================] - 0s 125us/step - loss: 0.3451 - acc: 0.9716 - val_loss: 0.5198 - val_acc: 0.9145\n",
            "Epoch 166/200\n",
            "282/282 [==============================] - 0s 119us/step - loss: 0.3439 - acc: 0.9716 - val_loss: 0.5187 - val_acc: 0.9145\n",
            "Epoch 167/200\n",
            "282/282 [==============================] - 0s 124us/step - loss: 0.3427 - acc: 0.9716 - val_loss: 0.5177 - val_acc: 0.9145\n",
            "Epoch 168/200\n",
            "282/282 [==============================] - 0s 196us/step - loss: 0.3416 - acc: 0.9716 - val_loss: 0.5167 - val_acc: 0.9145\n",
            "Epoch 169/200\n",
            "282/282 [==============================] - 0s 134us/step - loss: 0.3404 - acc: 0.9716 - val_loss: 0.5157 - val_acc: 0.9145\n",
            "Epoch 170/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.3392 - acc: 0.9716 - val_loss: 0.5147 - val_acc: 0.9145\n",
            "Epoch 171/200\n",
            "282/282 [==============================] - 0s 134us/step - loss: 0.3381 - acc: 0.9716 - val_loss: 0.5137 - val_acc: 0.9145\n",
            "Epoch 172/200\n",
            "282/282 [==============================] - 0s 114us/step - loss: 0.3369 - acc: 0.9716 - val_loss: 0.5126 - val_acc: 0.9145\n",
            "Epoch 173/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.3358 - acc: 0.9716 - val_loss: 0.5117 - val_acc: 0.9145\n",
            "Epoch 174/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.3346 - acc: 0.9716 - val_loss: 0.5107 - val_acc: 0.9145\n",
            "Epoch 175/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.3335 - acc: 0.9716 - val_loss: 0.5097 - val_acc: 0.9145\n",
            "Epoch 176/200\n",
            "282/282 [==============================] - 0s 108us/step - loss: 0.3324 - acc: 0.9716 - val_loss: 0.5087 - val_acc: 0.9145\n",
            "Epoch 177/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.3313 - acc: 0.9716 - val_loss: 0.5077 - val_acc: 0.9145\n",
            "Epoch 178/200\n",
            "282/282 [==============================] - 0s 121us/step - loss: 0.3302 - acc: 0.9716 - val_loss: 0.5068 - val_acc: 0.9145\n",
            "Epoch 179/200\n",
            "282/282 [==============================] - 0s 120us/step - loss: 0.3290 - acc: 0.9716 - val_loss: 0.5059 - val_acc: 0.9145\n",
            "Epoch 180/200\n",
            "282/282 [==============================] - 0s 126us/step - loss: 0.3279 - acc: 0.9716 - val_loss: 0.5049 - val_acc: 0.9145\n",
            "Epoch 181/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.3269 - acc: 0.9716 - val_loss: 0.5040 - val_acc: 0.9145\n",
            "Epoch 182/200\n",
            "282/282 [==============================] - 0s 111us/step - loss: 0.3258 - acc: 0.9716 - val_loss: 0.5031 - val_acc: 0.9145\n",
            "Epoch 183/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.3247 - acc: 0.9716 - val_loss: 0.5021 - val_acc: 0.9145\n",
            "Epoch 184/200\n",
            "282/282 [==============================] - 0s 128us/step - loss: 0.3236 - acc: 0.9716 - val_loss: 0.5012 - val_acc: 0.9145\n",
            "Epoch 185/200\n",
            "282/282 [==============================] - 0s 126us/step - loss: 0.3225 - acc: 0.9716 - val_loss: 0.5003 - val_acc: 0.9145\n",
            "Epoch 186/200\n",
            "282/282 [==============================] - 0s 114us/step - loss: 0.3215 - acc: 0.9716 - val_loss: 0.4994 - val_acc: 0.9145\n",
            "Epoch 187/200\n",
            "282/282 [==============================] - 0s 115us/step - loss: 0.3204 - acc: 0.9716 - val_loss: 0.4985 - val_acc: 0.9145\n",
            "Epoch 188/200\n",
            "282/282 [==============================] - 0s 105us/step - loss: 0.3194 - acc: 0.9716 - val_loss: 0.4976 - val_acc: 0.9145\n",
            "Epoch 189/200\n",
            "282/282 [==============================] - 0s 119us/step - loss: 0.3184 - acc: 0.9716 - val_loss: 0.4967 - val_acc: 0.9145\n",
            "Epoch 190/200\n",
            "282/282 [==============================] - 0s 137us/step - loss: 0.3174 - acc: 0.9716 - val_loss: 0.4958 - val_acc: 0.9145\n",
            "Epoch 191/200\n",
            "282/282 [==============================] - 0s 108us/step - loss: 0.3163 - acc: 0.9716 - val_loss: 0.4950 - val_acc: 0.9145\n",
            "Epoch 192/200\n",
            "282/282 [==============================] - 0s 113us/step - loss: 0.3153 - acc: 0.9716 - val_loss: 0.4941 - val_acc: 0.9145\n",
            "Epoch 193/200\n",
            "282/282 [==============================] - 0s 110us/step - loss: 0.3143 - acc: 0.9716 - val_loss: 0.4932 - val_acc: 0.9145\n",
            "Epoch 194/200\n",
            "282/282 [==============================] - 0s 117us/step - loss: 0.3133 - acc: 0.9716 - val_loss: 0.4923 - val_acc: 0.9145\n",
            "Epoch 195/200\n",
            "282/282 [==============================] - 0s 117us/step - loss: 0.3123 - acc: 0.9716 - val_loss: 0.4915 - val_acc: 0.9145\n",
            "Epoch 196/200\n",
            "282/282 [==============================] - 0s 129us/step - loss: 0.3113 - acc: 0.9716 - val_loss: 0.4906 - val_acc: 0.9145\n",
            "Epoch 197/200\n",
            "282/282 [==============================] - 0s 131us/step - loss: 0.3103 - acc: 0.9716 - val_loss: 0.4898 - val_acc: 0.9145\n",
            "Epoch 198/200\n",
            "282/282 [==============================] - 0s 134us/step - loss: 0.3093 - acc: 0.9716 - val_loss: 0.4890 - val_acc: 0.9145\n",
            "Epoch 199/200\n",
            "282/282 [==============================] - 0s 118us/step - loss: 0.3083 - acc: 0.9716 - val_loss: 0.4881 - val_acc: 0.9145\n",
            "Epoch 200/200\n",
            "282/282 [==============================] - 0s 108us/step - loss: 0.3074 - acc: 0.9716 - val_loss: 0.4873 - val_acc: 0.9145\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f14e0e8a1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDzwEsHHzUaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(feature_model.fit_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6GV6d6KroFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define default image size for VGG19\n",
        "image_size = (224, 224)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAvGPIbkfFTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path = os.path.join(\"sneaker_test.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiCS26Qgq8dj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1814e1a7-ec36-4ce9-acce-e6fb1495db78"
      },
      "source": [
        "x = data.process_image(image_path)\n",
        "x.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA-VC7q7sRMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "484581df-d133-4d1a-dc93-7d0416bb6426"
      },
      "source": [
        "predictions = feature_model.predict(x)\n",
        "print('Predicted:', decode_predictions(predictions, top=3))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-d42c569bd68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_3_input to have 2 dimensions, but got array with shape (1, 224, 224, 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYJBkhorsayf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}